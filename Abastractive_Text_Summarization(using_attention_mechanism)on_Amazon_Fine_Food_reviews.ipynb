{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Abastractive Text Summarization(using attention mechanism)on Amazon Fine Food reviews.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "e33CBaN_uEJl",
        "6zFTtVuouQsr",
        "qnaqBst1xN-9",
        "QvZQsH0QxqS0",
        "rz82XhceyK7k",
        "TWLuSyINzV9R",
        "KcHCsQodzhUK",
        "3hHwBeXd0qlv",
        "o_LrKnvv3EXB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxPPLwXl31y-",
        "colab_type": "text"
      },
      "source": [
        "#  Objective: To generate a summary for the Amazon Fine Food reviews using the abstraction-based (attention) approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_-ZHZPH4Qun",
        "colab_type": "text"
      },
      "source": [
        "# 1.Import the Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuhZqK7g3Buh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np  \n",
        "import pandas as pd \n",
        "import re           \n",
        "from bs4 import BeautifulSoup \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esPBZgea4mjp",
        "colab_type": "text"
      },
      "source": [
        "# 2.Read the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsAk1eix4gpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(\"/content/drive/My Drive/amazon.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llgyf6iG5NQu",
        "colab_type": "code",
        "outputId": "03e2a486-c6f7-4935-b27c-d74196766939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4986, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcMx1a9P7Im9",
        "colab_type": "code",
        "outputId": "23abca5b-0677-45ec-ee1e-7764537cd29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2546</td>\n",
              "      <td>2774</td>\n",
              "      <td>B00002NCJC</td>\n",
              "      <td>A196AJHU9EASJN</td>\n",
              "      <td>Alex Chaffee</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1282953600</td>\n",
              "      <td>thirty bucks?</td>\n",
              "      <td>Why is this $[...] when the same product is available for $[...] here?&lt;br /&gt;http://www.amazon.com/VICTOR-FLY-MAGNET-BAIT-REFILL/dp/B00004RBDY&lt;br /&gt;&lt;br /&gt;The Victor M380 and M502 traps are unreal, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2547</td>\n",
              "      <td>2775</td>\n",
              "      <td>B00002NCJC</td>\n",
              "      <td>A13RRPGE79XFFH</td>\n",
              "      <td>reader48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1281052800</td>\n",
              "      <td>Flies Begone</td>\n",
              "      <td>We have used the Victor fly bait for 3 seasons.  Can't beat it.  Great product!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1145</td>\n",
              "      <td>1244</td>\n",
              "      <td>B00002Z754</td>\n",
              "      <td>A3B8RCEI0FXFI6</td>\n",
              "      <td>B G Chase</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>962236800</td>\n",
              "      <td>WOW Make your own 'slickers' !</td>\n",
              "      <td>I just received my shipment and could hardly wait to try this product. We love &amp;quot;slickers&amp;quot; which is what we call them, instead of stickers because they can be removed so easily. My daught...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1146</td>\n",
              "      <td>1245</td>\n",
              "      <td>B00002Z754</td>\n",
              "      <td>A29Z5PI9BW2PU3</td>\n",
              "      <td>Robbie</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>961718400</td>\n",
              "      <td>Great Product</td>\n",
              "      <td>This was a really good idea and the final product is outstanding. I use the decals on my car window and everybody asks where i bought the decals i made.  Two thumbs up!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2942</td>\n",
              "      <td>3204</td>\n",
              "      <td>B000084DVR</td>\n",
              "      <td>A1UGDJP1ZJWVPF</td>\n",
              "      <td>T. Moore \"thoughtful reader\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1177977600</td>\n",
              "      <td>Good stuff!</td>\n",
              "      <td>I'm glad my 45lb cocker/standard poodle puppy loves the stuff because I trust the brand and its superior nutrition. Compare labels! My previous feed (Pedigree) was mostly corn. My little dude is h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                                                                                                                                                                                     Text\n",
              "0        2546  ...  Why is this $[...] when the same product is available for $[...] here?<br />http://www.amazon.com/VICTOR-FLY-MAGNET-BAIT-REFILL/dp/B00004RBDY<br /><br />The Victor M380 and M502 traps are unreal, ...\n",
              "1        2547  ...                                                                                                                          We have used the Victor fly bait for 3 seasons.  Can't beat it.  Great product!\n",
              "2        1145  ...  I just received my shipment and could hardly wait to try this product. We love &quot;slickers&quot; which is what we call them, instead of stickers because they can be removed so easily. My daught...\n",
              "3        1146  ...                                 This was a really good idea and the final product is outstanding. I use the decals on my car window and everybody asks where i bought the decals i made.  Two thumbs up!\n",
              "4        2942  ...  I'm glad my 45lb cocker/standard poodle puppy loves the stuff because I trust the brand and its superior nutrition. Compare labels! My previous feed (Pedigree) was mostly corn. My little dude is h...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGxKgKf86d-m",
        "colab_type": "text"
      },
      "source": [
        "# 3.Drop Duplicates and NA values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXFHtFMU6dlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop_duplicates(subset=['Text'],inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vmJJ7ze5aB1",
        "colab_type": "code",
        "outputId": "faf094a2-486d-4eae-9dad-39726550588a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 4985 entries, 0 to 4985\n",
            "Data columns (total 11 columns):\n",
            "Unnamed: 0                4985 non-null int64\n",
            "Id                        4985 non-null int64\n",
            "ProductId                 4985 non-null object\n",
            "UserId                    4985 non-null object\n",
            "ProfileName               4985 non-null object\n",
            "HelpfulnessNumerator      4985 non-null int64\n",
            "HelpfulnessDenominator    4985 non-null int64\n",
            "Score                     4985 non-null int64\n",
            "Time                      4985 non-null int64\n",
            "Summary                   4985 non-null object\n",
            "Text                      4985 non-null object\n",
            "dtypes: int64(6), object(5)\n",
            "memory usage: 467.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaEY5KXS8hkY",
        "colab_type": "text"
      },
      "source": [
        "# 4.Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_aE4TkT8xD5",
        "colab_type": "text"
      },
      "source": [
        "Here is the dictionary that we will use for expanding the contractions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrvcFoIc8VYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJQwV7Hwsxlq",
        "colab_type": "code",
        "outputId": "85f9ce85-a490-4632-80d0-5cdd1e504189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install NLTK"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: NLTK in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from NLTK) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98-cTtQx8_uB",
        "colab_type": "text"
      },
      "source": [
        "We will perform the below preprocessing tasks for our data:\n",
        "\n",
        "1.Convert everything to lowercase\n",
        "\n",
        "2.Remove HTML tags\n",
        "\n",
        "3.Contraction mapping\n",
        "\n",
        "4.Remove (‘s)\n",
        "\n",
        "5.Remove any text inside the parenthesis ( )\n",
        "\n",
        "6.Eliminate punctuations and special characters\n",
        "\n",
        "7.Remove stopwords\n",
        "\n",
        "8.Remove short words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iXQ1i1K9C8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def text_cleaner(text,num):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    if(num==0):\n",
        "        tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    else:\n",
        "        tokens=newString.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 \n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1D2a3s_tMiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t,0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g-MjRdFtbjw",
        "colab_type": "code",
        "outputId": "229aaf86-0dc1-417f-9314-d734715987a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "cleaned_text[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['product available http www amazon com victor fly magnet bait refill dp rbdythe victor traps unreal course total fly genocide pretty stinky right nearby',\n",
              " 'used victor fly bait seasons cannot beat great product',\n",
              " 'received shipment could hardly wait try product love slickers call instead stickers removed easily daughter designed signs printed reverse use car windows printed beautifully going lot fun product windows everywhere surfaces like tv screens computer monitors',\n",
              " 'really good idea final product outstanding use decals car window everybody asks bought decals made two thumbs',\n",
              " 'glad lb cocker standard poodle puppy loves stuff trust brand superior nutrition compare labels previous feed mostly corn little dude healthy happy high energy glossy coat also superior nutrition produces smaller compact stools']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnNwKboLtxbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(text_cleaner(t,1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf9URHXWt3iI",
        "colab_type": "code",
        "outputId": "3ede3821-f48b-4030-ee50-367ddcd20ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "cleaned_summary[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thirty bucks',\n",
              " 'flies begone',\n",
              " 'wow make your own slickers',\n",
              " 'great product',\n",
              " 'good stuff',\n",
              " 'premium quality dog food',\n",
              " 'cats love it',\n",
              " 'nice big pieces big almond flavor',\n",
              " 'summer treat fat free guilt free',\n",
              " 'do not buy this product unless you are looking for shredded coconut']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Vi7UQSst5o9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e33CBaN_uEJl",
        "colab_type": "text"
      },
      "source": [
        "# 5.Drop empty rows\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8zK0THVt-Jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zFTtVuouQsr",
        "colab_type": "text"
      },
      "source": [
        "# 6.Understanding the distribution of the sequences¶\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vP9QZr-uMzj",
        "colab_type": "code",
        "outputId": "1873f219-3148-47e2-a09b-080b7151be6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wMWxB6pvEJU8QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10cE9elguhPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_text_len=30\n",
        "max_summary_len=8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ8SncuawgTu",
        "colab_type": "text"
      },
      "source": [
        "Let us select the reviews and summaries whose length falls below or equal to max_text_len and max_summary_len\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2469MfwwPZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IytsEUaLws2I",
        "colab_type": "text"
      },
      "source": [
        "Add the START and END special tokens at the beginning and end of the summary. Here, I have chosen sostok and eostok as START and END tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFAgqKjkwpdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIpNrspIw9FD",
        "colab_type": "text"
      },
      "source": [
        "we need to split our dataset into a training and validation set. We’ll use 90% of the dataset as the training data and evaluate the performance on the remaining 10%:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi3KDFdhw1GX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnaqBst1xN-9",
        "colab_type": "text"
      },
      "source": [
        "# 7.Preparing the Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StWGlP4rxSO9",
        "colab_type": "text"
      },
      "source": [
        "A tokenizer builds the vocabulary and converts a word sequence to an integer sequence.Build tokenizers for text and summary:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvZQsH0QxqS0",
        "colab_type": "text"
      },
      "source": [
        "##Text Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeQndRJkxC0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz82XhceyK7k",
        "colab_type": "text"
      },
      "source": [
        "## Rarewords and its Coverage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQMjcJ1tybJ2",
        "colab_type": "text"
      },
      "source": [
        "Here, we are defining the threshold to be 4 which means word whose count is below 4 is considered as a rare word\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4LI2HbFx0Lp",
        "colab_type": "code",
        "outputId": "1721bf9a-abef-4456-a256-1f0d99baeab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 69.62672575421851\n",
            "Total Coverage of rare words: 12.353396056192809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "969mNZOkzAIg",
        "colab_type": "text"
      },
      "source": [
        "Let us define the tokenizer with top most common words for reviews.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO4d33BXysRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY5KhvU2zNOA",
        "colab_type": "code",
        "outputId": "e80acd2c-93fb-4ae4-8a15-c305e02ef9ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_voc\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWLuSyINzV9R",
        "colab_type": "text"
      },
      "source": [
        "##Summary Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w7WDCtxzQd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcHCsQodzhUK",
        "colab_type": "text"
      },
      "source": [
        "###Rarewords and its Coverage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6LEepQ1zpQW",
        "colab_type": "text"
      },
      "source": [
        "Word whose count is below 6 is considered as a rare word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbkjeKsYzdCT",
        "colab_type": "code",
        "outputId": "cbb7346b-54ee-4a19-cd5d-5350eb36fc9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 87.55630630630631\n",
            "Total Coverage of rare words: 18.904211703317184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p01uyQTRz24w",
        "colab_type": "text"
      },
      "source": [
        "Let us define the tokenizer with top most common words for summary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-6w04t9zuXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOLXLaS-1Idb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bmytwUA5ap_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MEhxsmU5cGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hHwBeXd0qlv",
        "colab_type": "text"
      },
      "source": [
        "# 8.Model building\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB-Qq5RRz5-p",
        "colab_type": "code",
        "outputId": "98803f10-f1ef-4056-88e6-f971ddbde36f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 30, 100)      178300      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    22200       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 222)    133422      concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 2,919,022\n",
            "Trainable params: 2,919,022\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msCs3gdC01VI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6WGASb-2Pbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLCg-sB2SMA",
        "colab_type": "code",
        "outputId": "23e443bf-1f42-4697-9e8d-4b2c352280de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2315 samples, validate on 246 samples\n",
            "Epoch 1/50\n",
            "2315/2315 [==============================] - 44s 19ms/sample - loss: 2.7529 - val_loss: 2.2047\n",
            "Epoch 2/50\n",
            "2315/2315 [==============================] - 41s 18ms/sample - loss: 2.1553 - val_loss: 2.0817\n",
            "Epoch 3/50\n",
            "2315/2315 [==============================] - 41s 18ms/sample - loss: 1.9950 - val_loss: 1.9089\n",
            "Epoch 4/50\n",
            "2315/2315 [==============================] - 41s 18ms/sample - loss: 1.8918 - val_loss: 1.8746\n",
            "Epoch 5/50\n",
            "2315/2315 [==============================] - 41s 18ms/sample - loss: 1.8495 - val_loss: 1.8530\n",
            "Epoch 6/50\n",
            "2315/2315 [==============================] - 41s 18ms/sample - loss: 1.8279 - val_loss: 1.8330\n",
            "Epoch 7/50\n",
            "2315/2315 [==============================] - 42s 18ms/sample - loss: 1.7971 - val_loss: 1.8097\n",
            "Epoch 8/50\n",
            "2315/2315 [==============================] - 41s 18ms/sample - loss: 1.7656 - val_loss: 1.8166\n",
            "Epoch 9/50\n",
            "2315/2315 [==============================] - 41s 18ms/sample - loss: 1.7380 - val_loss: 1.8337\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_LrKnvv3EXB",
        "colab_type": "text"
      },
      "source": [
        "# 9.Understanding the Diagnostic plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dQUzF_z2kP8",
        "colab_type": "code",
        "outputId": "babde473-77b5-4b63-f931-a71edfb70a32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSMNdKaX8kIa7Ukr5IQ13pZTyQ/8f0u5rJAJXlBgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Zt82RC3Oc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzoXf0M83gDB",
        "colab_type": "text"
      },
      "source": [
        "#10.Inference¶\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D7fg0hG3YM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45SnikE932zq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnEcYnVk37U9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--Gn3neV3_7P",
        "colab_type": "code",
        "outputId": "8d71bead-4344-42e3-db4d-c18028b6b100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(0,100):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: sent two friend thank big fan thrilled get cinnamon chocolate babka said delicious \n",
            "Original summary: delicious \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: right amount blueberry flavor tea overwhelming love added sweeteners really need perfect way get water benefit antioxidants tea well \n",
            "Original summary: very refreshing \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: item great price tastes great thing could make product better little plastic cup \n",
            "Original summary: love it \n",
            "Predicted summary:  great hot\n",
            "\n",
            "\n",
            "Review: great popcorn good popping results wonderful flavor cannot help love order run recommend one \n",
            "Original summary: great \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: like find bottle convenient like taste would definitely buy considering healthy use sure \n",
            "Original summary: salt \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: love love love muffins moist delicious like best day bake nd day dry bit wonderful pop toaster oven warm good new complaint difficult find def worth every penny \n",
            "Original summary: best muffins in the \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: gross tried thinking would least taste like regular powdered mixes flavor fake sweetener dark chocolate box cups want drink \n",
            "Original summary: yuck all flavor no chocolate \n",
            "Predicted summary:  great hot\n",
            "\n",
            "\n",
            "Review: always pleased amazon packaging chips never broken always fresh really liked brand flavor chips tasty \n",
            "Original summary: great chips \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: dog allergy corn live small town found dog food contain corn perfect new pet well loves added bonus comes straight door \n",
            "Original summary: for dogs with \n",
            "Predicted summary:  hot dog\n",
            "\n",
            "\n",
            "Review: tic tacs great right orange flavor find cheaper store cents pack went recently bought anyone living ca \n",
            "Original summary: great \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: tea decaffeinated flavor tea case get couple tea bags mug hot water hot water true hot water slightly five minutes tea flavor disappointing \n",
            "Original summary: no but no taste \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: spice mix taste favorite restaurant use much smells perfect meat bean \n",
            "Original summary: taste at \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: wish fat free salad dressing ounce bottle great salad dressing tastes good flavorful regular dressing \n",
            "Original summary: fat free \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: lb bag oatmeal seemed like way much time went found uses many recipes make running high quality oatmeal much cheaper better anything found grocery store \n",
            "Original summary: great way to \n",
            "Predicted summary:  great hot\n",
            "\n",
            "\n",
            "Review: drink cups day italian french roast coffee wanted try lower acid version brand coffee smells tastes like vinegar totally better drinking water acid coffee \n",
            "Original summary: worst coffee ever \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: kind tea good taste smell like tea feel like thing chemical \n",
            "Original summary: of tea get it \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: love snacks whole grain organic also love fact snack cup like also noticed leave lot crumbs makes happy \n",
            "Original summary: yummy and \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: wow admit really yummy know sugar taste small little bars calories piece perfect afternoon treat need something sweet office \n",
            "Original summary: yummy \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: bit honey since kid seeing amazon made purchase good remember \n",
            "Original summary: just like was \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: fantastic cocoa flavors excellent personal favorite dark chocolate received keurig christmas present cocoa end work day mixing microwave pot stove warm chocolatey goodness order product \n",
            "Original summary: great \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: dog anything treats buying five pound bag lasts year dry easy put pocket last forever \n",
            "Original summary: yummy treats \n",
            "Predicted summary:  grove dog dog\n",
            "\n",
            "\n",
            "Review: subscription popchips arrived time damaged love fact receive great variety chips healthier time tasty satisfying way chips packed shipping perfect subscription way go course price right thank \n",
            "Original summary: treat of the \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: allergies itching dog foods cheap buy anywhere food crazy preservatives cause health problems food works allergies dog loves food \n",
            "Original summary: great dog food dogs love it \n",
            "Predicted summary:  dog dog\n",
            "\n",
            "\n",
            "Review: life gluten allergy sometimes seem however bisquick started making product things got lot tastes like bisquick works like bisquick hey bisquick gluten free perfect pancakes enough said \n",
            "Original summary: perfect pancakes \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: cafe find product wholesale anywhere free shipping days supplier could get small amounts product would take weeks thanks amazon \n",
            "Original summary: gluten free in \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: found product kettle chips fabulous found amazon local stores crisp tasty without salt \n",
            "Original summary: kettle chips \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: tried substitute sandwich could cut without ended pieces like chunks enough cream cheese ok rolls products would recommend \n",
            "Original summary: cannot them from \n",
            "Predicted summary:  great hot\n",
            "\n",
            "\n",
            "Review: received product much promised seeds grow plant great cat loves highly recommend product seller \n",
            "Original summary: great product and service \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: gevalia far best coffee market especially organic \n",
            "Original summary: is the best \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: chip addict far tastiest non homemade chips ever plus healthy problem cannot flavor favorite \n",
            "Original summary: yum \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: love hot chocolate nice creamy flavor price good love single packs flavor available locally \n",
            "Original summary: yummy \n",
            "Predicted summary:  great hot\n",
            "\n",
            "\n",
            "Review: item fast exactly ordered excellent shape safe shipping came back shop thanks \n",
            "Original summary: excellent item and service \n",
            "Predicted summary:  great hot\n",
            "\n",
            "\n",
            "Review: else need know oatmeal instant expensive store brand oatmeal maybe little tastier better texture something still oatmeal mm convenient \n",
            "Original summary: it is \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: love perfect gift love packaging great idea perfect gift \n",
            "Original summary: great gift \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: chocolate covered espresso beans wonderful chocolate dark rich bean inside delightful blend flavors enough really give \n",
            "Original summary: these are the best \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: tea usa know silk loose leaf oolong tea like name silk silk tongue tea warm taste makes feel wonderful well done tea \n",
            "Original summary: awesome \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: brought bottles one carry pocket home fell love vacation couple drops trick packs flavor hot food \n",
            "Original summary: love it \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: canned food real chunks chicken dogs love looks smells better human quality canned beef \n",
            "Original summary: for dogs dogs love it \n",
            "Predicted summary:  grove dog\n",
            "\n",
            "\n",
            "Review: good snack feel great offering month old easily pick small pieces definitely enjoys apple cinnamon taste year old loves well would definitely recommend anyone small kids \n",
            "Original summary: great healthy snack \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: shortbread cookies delicious bought summer hard find expensive usa \n",
            "Original summary: cookies \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: like oreo oreo got try double stuff best side note shipping maybe better \n",
            "Original summary: the \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: purchased baby shower worked perfect small bags candy purchased want small bags would purchase larger bag \n",
            "Original summary: great \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: area one cannot find cinnamon happy able find flavor love product \n",
            "Original summary: good \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: makes best vinegar oil dressing ever couple rest oil good \n",
            "Original summary: best stuff ever \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: different flavors different people everyone going like others like love coffee totally give stars enjoy coffee lot price reasonable opinion local big box grocery store \n",
            "Original summary: blend is good coffee \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: food great dogs year old puppy soft hardly ever get sick food good especially amazon prime shipping \n",
            "Original summary: mm mm good \n",
            "Predicted summary:  grove dog\n",
            "\n",
            "\n",
            "Review: shipped nice package complain seller plant growing bigger looking bigger pot good looking plant needs minimal plant might need \n",
            "Original summary: like it \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: bought mostly wanted peppermint hot cocoa fell love milk chocolate one peppermint pretty good well good cocoa \n",
            "Original summary: great \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: love love green tea hard find area places internet charge big price usually get many boxes definitely order seller thanks green tea fix everyday \n",
            "Original summary: tea review \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: cups son wanted price excellent flavor rich would recommend anyone wanting good cup instant hot cocoa \n",
            "Original summary: delicious \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: received ingredients timely manner ingredients nicely packed fresh shipping needed meal making plenty left ingredients \n",
            "Original summary: and fresh \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: favorite bars ever dark choc wonderful filling hard find stores thankful save \n",
            "Original summary: best bar \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: love buying drinking workout lose vitamins helps water good love post workout also good anytime could use sweet natural drink \n",
            "Original summary: delicious \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: addicting fantastic snack mix wonderful variety crackers blend flavors \n",
            "Original summary: wonderful blend of flavors \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: used candy birthday party kids loved full size still cute \n",
            "Original summary: great for \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: kettle chips taste good crispy crunchy enjoy also cut \n",
            "Original summary: kettle chips \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: first love packaging making would problem ordered winter cold also want thank free sample delicious love \n",
            "Original summary: this item is awesome \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: chips salty like crunch size bags variety cannot finish case due salty chips \n",
            "Original summary: too \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: kids like cocoa perfect cannot make kids hot tastes good count bad \n",
            "Original summary: cannot \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: ordered months ago find basically acid read ingredients main label says olive juice thing going suggest amazon take website \n",
            "Original summary: not really \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: product helped friend able eat going college finding things eat hard send supply every month make food get sick \n",
            "Original summary: good for \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: taste whole wheat muffins great taste good chocolate flavor texture add chopped \n",
            "Original summary: best \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: delicious popcorn lost star use hot air popper many popping great flavor great texture tender add anything even though purchased three different flavored thanks \n",
            "Original summary: delicious popcorn \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: bought brands try found one much less chocolate taste cafe escapes dark chocolate also thinner consistency buy \n",
            "Original summary: not as good as \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: ordered amazon recommended go along popcorn popper got hey actually pop small kernels get thrown popper absolute waste money \n",
            "Original summary: but \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: tried bars good although like peanut butter chocolate chip bars better bars quick easy carry snack go \n",
            "Original summary: and bars \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: free chips see regular chip cravings remind munchos less greasy try \n",
            "Original summary: healthy and tasty \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: though fresh moist however personally sweet think stick brand brand expensive seems taste better \n",
            "Original summary: good \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: nice alternative apple pie love fact easy prepare also loved fact make fresh whenever needed \n",
            "Original summary: loved these \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: bought give party favors son baseball themed birthday party huge hit adults children \n",
            "Original summary: great item \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: coffee years ago lived glad get amazon strong full bodied easy tummy \n",
            "Original summary: delicious \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: love strawberries chocolate locally could find dark chocolate type glad found amazon wonderful \n",
            "Original summary: much better than chocolate \n",
            "Predicted summary:  great hot\n",
            "\n",
            "\n",
            "Review: really enjoy product hard time finding affordable store found look sugar use thanks much \n",
            "Original summary: sugar in the \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: need gluten free non dairy egg pretty use really work split great mini \n",
            "Original summary: pretty good \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: like lot gf mixes make whole box keep fridge pop em toaster oven morning \n",
            "Original summary: best gf pancakes \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: stuff really works middle pop water bottle set flavor fine goes easy \n",
            "Original summary: great for \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: one perfect box inside box dented cans chowder looked like fell every single disappointed return chowder good rate star box \n",
            "Original summary: from \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: big fan flour baked gives everything bit adds extra bit sweet baking highly recommend baking flour mixes may want add savory recipes though light sweet flavor \n",
            "Original summary: best for \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: well packed broken cookies tasty interesting friends really enjoyed \n",
            "Original summary: very good \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: favorite gluten free dairy free flavored chips many salt vinegar chips contain dairy nice find ones eat vinegar flavor really intense good \n",
            "Original summary: best gluten free free chips \n",
            "Predicted summary:  great hot\n",
            "\n",
            "\n",
            "Review: organic find reasonable price love amazon makes perfect affordable snack \n",
            "Original summary: perfect for little \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: know fault packaging past prime hard flavor strong enough \n",
            "Original summary: of \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: gluten allergies great biscuits pancakes taste much regular bisquick problem comes small size would love box larger \n",
            "Original summary: gluten free bisquick \n",
            "Predicted summary:  grove dog\n",
            "\n",
            "\n",
            "Review: cans dented way however cheaper purchasing product \n",
            "Original summary: little \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: love cream cheese even great way enjoy caviar break \n",
            "Original summary: great tasty and on \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: love white corn including popcorn hate expensive kernels supermarket love popcorn \n",
            "Original summary: yummy popcorn \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: recieved product time excellent shape tastes good expectations thanks excellent service \n",
            "Original summary: grove square cups \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: strong smooth flavor mahogany color get drinking absolutely best found favorite \n",
            "Original summary: fantastic stuff \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: sugar raw flavor much better white sugar better something wish bags \n",
            "Original summary: it is sugar \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: long time since eaten decided give try always left size simply enjoy every bit one serving \n",
            "Original summary: for \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: times always find returning coffee flavor product anymore flavor coffee exceptional full rich shelf coffee ever tasted highly recommended \n",
            "Original summary: coffee \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: bought many times good quality good taste baby love love \n",
            "Original summary: good taste baby love it \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: good stuff like need small feel good mouth \n",
            "Original summary: beans \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: hands absolute best salt vinegar chips buy great strong flavor left addicted certainly favorite chips highly recommend trying \n",
            "Original summary: the salt vinegar \n",
            "Predicted summary:  great hot\n",
            "\n",
            "\n",
            "Review: yum convenience expect cup flavor real hot chocolate kids love \n",
            "Original summary: easy and kids love it \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: popchips great fresh arrived price wish bags chips bucks \n",
            "Original summary: pop chips \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: produce extremely fresh made delicious thai soup items plenty \n",
            "Original summary: excellent \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: got wine chocolates use part stocking stuffers yummy big hit everyone would definitely buy \n",
            "Original summary: excellent \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: great alternative chips sure would based reviews glad bought wish would found month cannot get enough like \n",
            "Original summary: fantastic \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: well big red fan bought first let tell price amazing mean else get type deal everyone loved course next shipment get \n",
            "Original summary: amazing \n",
            "Predicted summary:  great\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ9TKffD4DXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}